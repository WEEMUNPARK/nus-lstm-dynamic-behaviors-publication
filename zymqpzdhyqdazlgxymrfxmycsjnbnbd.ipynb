{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fdd453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 03:17:50.618540: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-08-31 03:17:50.620672: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-08-31 03:17:50.622321: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-24.999924650573853\n",
      "-24.999976762784335\n",
      "-24.99985990758179\n",
      "-24.999863063512077\n",
      "-24.99991449147376\n",
      "-24.999255892267257\n",
      "-24.999845819962417\n",
      "-24.999908580156397\n",
      "-24.999888873881552\n",
      "-24.99935118147492\n",
      "-24.999976796072726\n",
      "-24.999975406490915\n",
      "-24.99984012256182\n",
      "-24.999956561248318\n",
      "-24.999955492891644\n",
      "-24.999524294663836\n",
      "-24.999967134767136\n",
      "-24.999967942672136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_ft_vec\n",
      "  return self.ufunc(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_it_vec\n",
      "  return self.ufunc(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_ot_vec\n",
      "  return self.ufunc(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-24.999875532206268\n",
      "-24.999975544850518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 03:21:25.672573: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-08-31 03:21:25.675029: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-08-31 03:21:25.676758: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-24.999966756571588\n",
      "-24.999990448228495\n",
      "-24.99981621049198\n",
      "-24.99992065848036\n",
      "-24.999973894839563\n",
      "-24.999677325825807\n",
      "-24.999498233943193\n",
      "-24.999974716244957\n",
      "-24.99984235249984\n",
      "-24.999843860387468\n",
      "-24.99972725344326\n",
      "-24.99988124666528\n",
      "-24.99931646556094\n",
      "-24.999922583009727\n",
      "-24.99997245266143\n",
      "-24.999804478707876\n",
      "-24.999413305743797\n",
      "-24.999976979553825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_ft_vec\n",
      "  return self.ufunc(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_it_vec\n",
      "  return self.ufunc(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_ot_vec\n",
      "  return self.ufunc(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-24.999889840974905\n",
      "-24.99945976045337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 03:25:00.870821: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-08-31 03:25:00.872941: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-08-31 03:25:00.874634: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-24.99996940744056\n",
      "-24.999960974854353\n",
      "-24.999343913012634\n",
      "-24.99931673152496\n",
      "-24.999978350276074\n",
      "-24.999386154576655\n",
      "-24.999348103979163\n",
      "-24.99960291503725\n",
      "-24.999424665379866\n",
      "-24.999490211521273\n",
      "-24.999402253852253\n",
      "-24.999967530281808\n",
      "-24.99937394311062\n",
      "-24.999966290119897\n",
      "-24.999957528848988\n",
      "-24.999959242943184\n",
      "-24.999390423546206\n",
      "-24.9998902358865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_ft_vec\n",
      "  return self.ufunc(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_it_vec\n",
      "  return self.ufunc(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_ot_vec\n",
      "  return self.ufunc(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-24.99928924821519\n",
      "-24.99938278039055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 03:28:36.598222: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-08-31 03:28:36.600342: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-08-31 03:28:36.601930: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-24.999963833133723\n",
      "-24.999940618548358\n",
      "-24.999718698311455\n",
      "-24.999854892231742\n",
      "-24.999714882668368\n",
      "-24.99989303258951\n",
      "-24.999528562764784\n",
      "-24.999819043759924\n",
      "-24.999485580293666\n",
      "-24.999688794409646\n",
      "-24.999739863496767\n",
      "-24.999717607960537\n",
      "-24.999679509228038\n",
      "-24.999927462222022\n",
      "-24.999933016887894\n",
      "-24.99929353562633\n",
      "-24.999389723814335\n",
      "-24.999479351557046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_ft_vec\n",
      "  return self.ufunc(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_it_vec\n",
      "  return self.ufunc(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_ot_vec\n",
      "  return self.ufunc(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-24.999470549320797\n",
      "-24.999294455041227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 03:32:10.908773: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-08-31 03:32:10.910863: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-08-31 03:32:10.912524: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-24.999910528122033\n",
      "-24.99996515827304\n",
      "-24.999332372602538\n",
      "-24.999374383560152\n",
      "-24.999934103693626\n",
      "-24.99979442897844\n",
      "-24.99918366393235\n",
      "-24.999793898683038\n",
      "-24.99910421784019\n",
      "-24.999493592883276\n",
      "-24.99937540651118\n",
      "-24.999971500403046\n",
      "-24.99919445363104\n",
      "-24.999955287105294\n",
      "-24.99998621758837\n",
      "-24.999960102624232\n",
      "-24.999312642982638\n",
      "-24.999882609299373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_ft_vec\n",
      "  return self.ufunc(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_it_vec\n",
      "  return self.ufunc(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_ot_vec\n",
      "  return self.ufunc(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-24.999896566845067\n",
      "-24.999240837868633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 03:35:43.420081: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-08-31 03:35:43.422158: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-08-31 03:35:43.423760: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-24.999884363326426\n",
      "-24.99994738074513\n",
      "-24.999803869817196\n",
      "-24.999772235130035\n",
      "-24.999773579545774\n",
      "-24.999867935529426\n",
      "-24.999807435481618\n",
      "-24.99968065709686\n",
      "-24.999682826753595\n",
      "-24.9999193853765\n",
      "-24.99997649693447\n",
      "-24.999936396216672\n",
      "-24.999759759330985\n",
      "-24.999972443409\n",
      "-24.999992770739194\n",
      "-24.999968393814303\n",
      "-24.999965992163744\n",
      "-24.999380173233348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_ft_vec\n",
      "  return self.ufunc(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_it_vec\n",
      "  return self.ufunc(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py:170: RuntimeWarning: overflow encountered in get_ot_vec\n",
      "  return self.ufunc(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-24.999627815712653\n",
      "-24.999971920695156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 03:39:14.183143: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-08-31 03:39:14.184991: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-08-31 03:39:14.186728: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-24.999918276304935\n",
      "-24.999961373339485\n",
      "-24.999894142704356\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import models, Model\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.colors import ListedColormap\n",
    "import multiprocessing\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, Model\n",
    "import numpy as np\n",
    "from numba import guvectorize,cuda,jit\n",
    "\n",
    "def get_mean_vector(h_set):\n",
    "    \"\"\"\n",
    "    :param h_set: list of vectors h, each vector is output of LSTM layer at a timestep\n",
    "    :return: mean vector hbar\n",
    "    \"\"\"\n",
    "    hbar = h_set[0]\n",
    "    for i in range(1, len(h_set)):\n",
    "        hbar += h_set[i]\n",
    "    hbar = hbar / len(h_set)\n",
    "    return hbar\n",
    "\n",
    "def get_magnitude(vector):\n",
    "    \"\"\"\n",
    "    :param vector: 1D numpy array\n",
    "    :return: magnitude of vector\n",
    "    \"\"\"\n",
    "    magnitude = 0\n",
    "    for element in vector:\n",
    "        magnitude += element ** 2\n",
    "    return math.sqrt(magnitude)\n",
    "\n",
    "def get_norm(vector):\n",
    "    \"\"\"\n",
    "    :param vector: vector to normalise\n",
    "    :return: norm of vector\n",
    "    \"\"\"\n",
    "    return vector / get_magnitude(vector)\n",
    "\n",
    "def project(vector, basis):\n",
    "    \"\"\"\n",
    "    :param vector: vector to project onto basis\n",
    "    :param basis: basis for poincare map\n",
    "    :return: vector projected onto basis (dot product)\n",
    "    \"\"\"\n",
    "    return vector.dot(basis)\n",
    "\n",
    "def get_poincare_mapping(lstm, start, num_steps, intermediate_inputs=None):\n",
    "    \"\"\"\n",
    "    get poincare mapping (projections at h_t, projections at h_{t+1})\n",
    "    :param lstm: trained LSTM_layer\n",
    "    :param start: starting input\n",
    "    :param num_steps: number of iterations to perform, length of intermediate_inputs has to be num_steps - 1\n",
    "    :param intermediate_inputs: list of x_t to input at each timestep, zero vectors if None, each vector has to be length start\n",
    "    :return: poincare mapping\n",
    "    \"\"\"\n",
    "    if intermediate_inputs is None:\n",
    "        intermediate_inputs = [np.zeros(len(start), dtype=np.float64) for _ in range(num_steps - 1)]\n",
    "\n",
    "    # get h_t at each timestep\n",
    "    h_t = [lstm.step(start)[-1]]\n",
    "    h_t_1 = [] # h_{t+1}\n",
    "    for i in range(num_steps - 1):\n",
    "        curr_h = lstm.step(intermediate_inputs[i])[-1]\n",
    "        h_t.append(curr_h)\n",
    "        h_t_1.append(curr_h)\n",
    "\n",
    "    h_t.pop() # remove last element so h_t and h_{t+1} aligns\n",
    "    return h_t, h_t_1\n",
    "\n",
    "def main(n):       \n",
    "    # numbers setup\n",
    "    class LSTM_layer():\n",
    "        @staticmethod\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        @staticmethod\n",
    "        def tanh(x): # for consistency\n",
    "            return np.tanh(x)\n",
    "\n",
    "        def __init__(self, weights):\n",
    "            \"\"\"\n",
    "            :param weights: weights of LSTM layer\n",
    "            \"\"\"\n",
    "            # transposing matrices for dot product\n",
    "            self.W, self.U, self.b = np.transpose(weights[0]), np.transpose(weights[1]), np.transpose(weights[2])\n",
    "            self.num_units = int(self.U.shape[1])\n",
    "            self.split_weights()\n",
    "            # LSTM trained stateless, initial C and h are zero vectors\n",
    "            self.C = np.zeros((self.num_units), dtype=np.float64)\n",
    "            self.h = np.zeros((self.num_units), dtype=np.float64)\n",
    "\n",
    "        def split_weights(self):\n",
    "            # weights are stored as (neuron_num, (i, f, c, o))\n",
    "            self.W_i = np.ascontiguousarray(self.W[:self.num_units, :])\n",
    "            self.W_f = np.ascontiguousarray(self.W[self.num_units:self.num_units * 2, :])\n",
    "            self.W_c = np.ascontiguousarray(self.W[self.num_units * 2:self.num_units * 3, :])\n",
    "            self.W_o = np.ascontiguousarray(self.W[self.num_units * 3:, :])\n",
    "\n",
    "            self.U_i = np.ascontiguousarray(self.U[:self.num_units, :])\n",
    "            self.U_f = np.ascontiguousarray(self.U[self.num_units:self.num_units * 2, :])\n",
    "            self.U_c = np.ascontiguousarray(self.U[self.num_units * 2:self.num_units * 3, :])\n",
    "            self.U_o = np.ascontiguousarray(self.U[self.num_units * 3:, :])\n",
    "\n",
    "            self.b_i = np.ascontiguousarray(self.b[:self.num_units])\n",
    "            self.b_f = np.ascontiguousarray(self.b[self.num_units:self.num_units * 2])\n",
    "            self.b_c = np.ascontiguousarray(self.b[self.num_units * 2:self.num_units * 3])\n",
    "            self.b_o = np.ascontiguousarray(self.b[self.num_units * 3:])\n",
    "\n",
    "        def step(self, x_t):\n",
    "            \"\"\"\n",
    "            Performs a timestep (propagating new input through layer)\n",
    "            :return: array of activations [ft, it, cc, cc_update, c_out, ot, ht]\n",
    "            \"\"\"\n",
    "            activations = []\n",
    "            # forget step\n",
    "            ft = self.get_ft(x_t)\n",
    "            activations.append(ft)\n",
    "            self.forget(ft)\n",
    "\n",
    "            # \"remembering\" step\n",
    "            it = self.get_it(x_t)\n",
    "            activations.append(it)\n",
    "            cc = self.get_CC(x_t)\n",
    "            activations.append(cc)\n",
    "            cc_update = self.get_CC_update(it, cc)\n",
    "            activations.append(cc_update)\n",
    "            self.remember(cc_update)\n",
    "\n",
    "            # output step\n",
    "            c_out = self.get_C_output()\n",
    "            activations.append(c_out)\n",
    "            ot = self.get_ot(x_t)\n",
    "            activations.append(ot)\n",
    "            output = self.output(c_out, ot)\n",
    "            activations.append(output)\n",
    "\n",
    "            return activations\n",
    "\n",
    "        def reset(self):\n",
    "            # call when done with one input (with all timesteps completed)\n",
    "            # resets internal cell state and starting hidden state\n",
    "            self.C = np.zeros((self.num_units), dtype=np.float64)\n",
    "            self.h = np.zeros((self.num_units), dtype=np.float64)\n",
    "\n",
    "\n",
    "        # vectorized activation propagation\n",
    "        @staticmethod\n",
    "        @guvectorize(\n",
    "            [\"float64[:, :], float64[:, :], float64[:], float64[:], float64[:], float64[:]\"],\n",
    "            \"(n, m),(n, n),(m),(n),(n)->(n)\"\n",
    "  \n",
    "        )\n",
    "        def get_ft_vec(W_f, U_f, x_t, h, b_f, res):\n",
    "            wfx = W_f.dot(x_t)\n",
    "            ufh = U_f.dot(h)\n",
    "            sum_int = wfx + ufh\n",
    "            sum_f = sum_int + b_f\n",
    "            res[:] = 1 / (1 + np.exp(-sum_f))\n",
    "\n",
    "        @staticmethod\n",
    "        @guvectorize(\n",
    "            [\"float64[:, :], float64[:, :], float64[:], float64[:], float64[:], float64[:]\"],\n",
    "            \"(n, m),(n, n),(m),(n),(n)->(n)\"\n",
    "    \n",
    "        )\n",
    "        def get_it_vec(W_i, U_i, x_t, h, b_i, res):\n",
    "            wix = W_i.dot(x_t)\n",
    "            uih = U_i.dot(h)\n",
    "            sum_int = wix + uih\n",
    "            sum_f = sum_int + b_i\n",
    "            res[:] = 1 / (1 + np.exp(-sum_f))\n",
    "\n",
    "        @staticmethod\n",
    "        @guvectorize(\n",
    "            [\"float64[:, :], float64[:, :], float64[:], float64[:], float64[:], float64[:]\"],\n",
    "            \"(n, m),(n, n),(m),(n),(n)->(n)\"\n",
    "     \n",
    "        )\n",
    "        def get_CC_vec(W_c, U_c, x_t, h, b_c, res):\n",
    "            wcx = W_c.dot(x_t)\n",
    "            uch = U_c.dot(h)\n",
    "            sum_int = wcx + uch\n",
    "            sum_f = sum_int + b_c\n",
    "            res[:] = np.tanh(sum_f)\n",
    "\n",
    "        @staticmethod\n",
    "        @guvectorize(\n",
    "            [\"float64[:, :], float64[:, :], float64[:], float64[:], float64[:], float64[:]\"],\n",
    "            \"(n, m),(n, n),(m),(n),(n)->(n)\"\n",
    "   \n",
    "        )\n",
    "        def get_ot_vec(W_o, U_o, x_t, h, b_o, res):\n",
    "            wox = W_o.dot(x_t)\n",
    "            uoh = U_o.dot(h)\n",
    "            sum_int = wox + uoh\n",
    "            sum_f = sum_int + b_o\n",
    "            res[:] = 1 / (1 + np.exp(-sum_f))\n",
    "\n",
    "        # activations start\n",
    "        # tanh activations don't see an improvement from vectorization (probably because tanh is already vectorized)\n",
    "        def get_ft(self, x_t):\n",
    "            # sigmoid(W_f . x_t + U_f . h_(t-1) + b_f) . is dot product\n",
    "            # wfx = self.W_f.dot(x_t)\n",
    "            # ufh = self.U_f.dot(self.h)\n",
    "            # return LSTM_layer.sigmoid(wfx + ufh + self.b_f)\n",
    "            return LSTM_layer.get_ft_vec(self.W_f, self.U_f, x_t, self.h, self.b_f)\n",
    "\n",
    "        def get_it(self, x_t):\n",
    "            # sigmoid(W_i . x_t + U_i . h_(t-1) + b_i)\n",
    "            # wix = self.W_i.dot(x_t)\n",
    "            # uih = self.U_i.dot(self.h)\n",
    "            # return LSTM_layer.sigmoid(wix + uih + self.b_i)\n",
    "            return LSTM_layer.get_it_vec(self.W_i, self.U_i, x_t, self.h, self.b_i)\n",
    "\n",
    "        def get_CC(self, x_t):\n",
    "            # candidate cell state before proportion\n",
    "            # tanh(W_c . x_t + U_c . h_(t-1) + b_c)\n",
    "            wcx = self.W_c.dot(x_t)\n",
    "            uch = self.U_c.dot(self.h)\n",
    "            return LSTM_layer.tanh(wcx + uch + self.b_c)\n",
    "            # return LSTM_layer.get_CC_vec(self.W_c, self.U_c, x_t, self.h, self.b_c)\n",
    "\n",
    "        def get_ot(self, x_t):\n",
    "            # sigmoid(W_o . x_t + U_o . h_(t-1) + b_o)\n",
    "            # wox = self.W_o.dot(x_t)\n",
    "            # uoh = self.U_o.dot(self.h)\n",
    "            # return LSTM_layer.sigmoid(wox + uoh + self.b_o)\n",
    "            return LSTM_layer.get_ot_vec(self.W_o, self.U_o, x_t, self.h, self.b_o)\n",
    "\n",
    "        def get_C_output(self):\n",
    "            # cell state output before proportion\n",
    "            # tanh(C_t)\n",
    "            return LSTM_layer.tanh(self.C)\n",
    "\n",
    "        def get_CC_update(self, it, cc):\n",
    "            # candidate cell state after proportion, for updating cell state\n",
    "            # it * cc, * is Hadamard product\n",
    "            return it * cc\n",
    "        # activations end\n",
    "\n",
    "\n",
    "        # state updates start\n",
    "        def forget(self, ft):\n",
    "            # update old cell state in the forget step\n",
    "            self.C = self.C * ft\n",
    "\n",
    "        def remember(self, cc_update):\n",
    "            # update old cell state with new information\n",
    "            self.C = self.C + cc_update\n",
    "\n",
    "        def output(self, c_output, ot):\n",
    "            # proportionate the cell output vector for new output and hidden state\n",
    "            self.h = c_output * ot\n",
    "            return self.h\n",
    "        # state updates end\n",
    "\n",
    "    \n",
    "    # state updates end\n",
    "    trace_length = 25 # number of newest lines to draw\n",
    "    ppf = 1 #4 # datapoints per frame\n",
    "    num_timesteps = 500\n",
    "    len_sequence = 75000\n",
    "    start_point = 0 #99500\n",
    "    end_point = 75000\n",
    "    num_cells = 60\n",
    "    av=[]\n",
    "    with open('paper(2 and3)/sample.pkl','rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    \n",
    "    #i=950\n",
    "\n",
    "        \n",
    "   # while i<1101:\n",
    "    \n",
    "    filepath='paper(2 and3)/paper2/weights.'+str(n)+'.hdf5'\n",
    "    model= models.load_model(filepath,compile=False)\n",
    "\n",
    "\n",
    "    #embed_layer = Model(inputs=model.input, outputs=model.layers[0].output)\n",
    "    lm=[]\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "\n",
    "            # if length[i] < 350:\n",
    "            #     continue\n",
    "            #x_in_gau = x[i].reshape((1, num_timesteps))+ random.gauss(0,1e-15)\n",
    "            #x_in_gau = x_in + random.gauss(0,0.0001)\n",
    "            #print(x_in[0])\n",
    "            #print(x_in_gau)\n",
    "\n",
    "\n",
    "                #print(lstm_in_gau.dtype,lstm_in_gau)\n",
    "                #lstm_in_late_gau[0][0][0]=0.01\n",
    "\n",
    "        a=model.layers[1].get_weights()\n",
    "        for e in range(len(a)):\n",
    "                a[e]=np.float64(a[e])\n",
    "        lstm = LSTM_layer(a)\n",
    "        start = dataset[i]\n",
    "            #print(np.array(start).shape)\n",
    "        start_gau=dataset[i]+np.float64(random.gauss(0,1e-8))\n",
    "                #print(lstm_in_late)\n",
    "            #print(start==start_gau)\n",
    "                #intermediate_steps = np.zeros((75000,32))\n",
    "        intermediate_steps = np.zeros((75000,32))\n",
    "            #print(intermediate_steps)\n",
    "        h_t_late, h_t_1_late = get_poincare_mapping(lstm, start, len_sequence, intermediate_steps)\n",
    "        h_t_late.append(h_t_1_late[-1])\n",
    "        hbar_late = get_mean_vector(h_t_late)\n",
    "\n",
    "        h_t_late_gau, h_t_1_late_gau = get_poincare_mapping(lstm, start_gau, len_sequence, intermediate_steps)\n",
    "                #print(h_t_late_gau[0])\n",
    "        h_t_late_gau.append(h_t_1_late_gau[-1])\n",
    "        late_set=[]\n",
    "\n",
    "                #print(len(h_t_late_gau))\n",
    "            #print(len(h_t_late))\n",
    "        for j in range(len(h_t_late)-10, len(h_t_late)):\n",
    "\n",
    "                    vec1=np.array(h_t_late[j])\n",
    "\n",
    "                    vec2=np.array(h_t_late_gau[j])\n",
    "                    dist = numpy.linalg.norm(vec1 - vec2)\n",
    "                    #if dist<1e-15:\n",
    "                        #dist=np.float64(0)\n",
    "                    #print(vec1.dtype,vec2.dtype,dist.dtype)\n",
    "                    #if dist<=np.finfo(np.float32).eps:\n",
    "                        #dist=np.float32(0)\n",
    "                    dist_late=numpy.log(dist+numpy.exp(-25))\n",
    "\n",
    "                    late_set.append(dist_late)\n",
    "\n",
    "        lm.append(np.mean(late_set))\n",
    "        print(np.mean(late_set))\n",
    "    return np.mean(lm)\n",
    "                #late=np.mean(late_set[-5:])\n",
    "            #print(n,late)\n",
    "            #av.append(late)\n",
    "            #i+=1\n",
    "        #pa='paper2/dtest/dattaa_'+str(n)+'.txt'\n",
    "        #np.savetxt(pa,av)\n",
    "        #return av\n",
    "            #if np.mean(late)<=np.float32(np.log(np.finfo(np.float32).eps)):\n",
    "                #me=np.float32(-25)\n",
    "\n",
    "\n",
    "            #plt.figure(figsize=(15,8)) \n",
    "            #plt.scatter(np.arange(len(late)),late,c='blue')\n",
    "            #plt.scatter(h_t_late_gau[0:-2],h_t_late_gau[1:-1],c='grey')\n",
    "            #plt.plot(h_t_late[-2],h_t_late[-1],'d',c='yellow')\n",
    "            #plt.plot(h_t_late_gau[-2],h_t_late[-1],'s',c='orange')\n",
    "            #plt.ylim(-30,2,32)\n",
    "            #plt.xlabel('len_sequence')\n",
    "            #plt.ylabel('log distance between ht` and ht')\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    #pool=multiprocessing.Pool(processes=8)\n",
    "    #for i in range(233,420):\n",
    "        #pool.apply_async(main, (i, ))\n",
    "        x=[]\n",
    "        for i in range(653,663):\n",
    "            x.append(main(i))\n",
    "        for i in range(833,843):\n",
    "            x.append(main(i))\n",
    "        for i in range(870,876):\n",
    "            x.append(main(i))\n",
    "\n",
    "    #pool.close()\n",
    "    #pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9feb8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7feb3e1d50>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "with open('l2wd/loss.pck','rb') as f:\n",
    "    loss=pickle.load(f)\n",
    "plt.plot(loss[368:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53e51344",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamade=np.random.normal(0,1e-5,size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e3d616b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datam(n):\n",
    "    d=[]\n",
    "    i=0\n",
    "    while i<n:\n",
    "        d.append(np.random.normal(0,2**i*1e-3,size=32).tolist())\n",
    "        i+=1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "325e8aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('paper(2 and3)/sample.pkl','wb') as f:\n",
    "    pickle.dump(datam(20),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f98e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('paper(2 and3)/sample.pkl','rb') as f:\n",
    "    x=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d8456dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0010564142559647378,\n",
       "  -0.0001385070031963872,\n",
       "  4.5505225510906e-05,\n",
       "  -0.001607492911455683,\n",
       "  -0.001331470127784811,\n",
       "  -0.000771747226771452,\n",
       "  0.0006995254839663351,\n",
       "  0.0012711230212304055,\n",
       "  0.0005811480197861473,\n",
       "  0.0005385030092574448,\n",
       "  0.0006459057527926832,\n",
       "  0.0021036205529749684,\n",
       "  0.0013771505412318796,\n",
       "  0.0003774921743539825,\n",
       "  0.0002262851820959016,\n",
       "  2.4915214424036057e-05,\n",
       "  0.000895186675567104,\n",
       "  0.00017142222700837373,\n",
       "  -0.000988276449269225,\n",
       "  -0.0008727504651516703,\n",
       "  -0.002548718825089243,\n",
       "  0.0003268078024932577,\n",
       "  0.0005847947756029775,\n",
       "  0.0008490106901954233,\n",
       "  0.000192306918140117,\n",
       "  -0.0007532023149546184,\n",
       "  0.0010489060530278582,\n",
       "  -0.0013379453102580223,\n",
       "  -0.0004509712855344037,\n",
       "  0.000278119767976552,\n",
       "  0.00031271009677878123,\n",
       "  -0.0004258764892820689],\n",
       " [0.0001420836005642428,\n",
       "  0.000933505251987307,\n",
       "  0.00013330705312301802,\n",
       "  0.001377081435777068,\n",
       "  -0.0027797288426796227,\n",
       "  0.0017634246379031797,\n",
       "  -0.0002505466378478722,\n",
       "  0.001567495208049852,\n",
       "  0.0011497878816887773,\n",
       "  0.0009429751061060425,\n",
       "  0.001928542196116125,\n",
       "  0.0013483740675622202,\n",
       "  -0.0007518951316714527,\n",
       "  -0.0012343485800899643,\n",
       "  0.00014286765679846403,\n",
       "  0.0032315005145255723,\n",
       "  0.0003159973833739043,\n",
       "  0.0015431296723719217,\n",
       "  -0.00023450465161528483,\n",
       "  -0.0009575926280604131,\n",
       "  -0.0026866100814546914,\n",
       "  0.0028053123785529792,\n",
       "  0.0018574982466397925,\n",
       "  0.0006865800096363627,\n",
       "  0.0022560586999048186,\n",
       "  0.002791120496626802,\n",
       "  -0.0004982565064244204,\n",
       "  0.0003833088945388986,\n",
       "  0.00043350107703989956,\n",
       "  -0.0012280619844232928,\n",
       "  -0.0009084659687849072,\n",
       "  0.0012162341143707102],\n",
       " [0.0035122193140598524,\n",
       "  0.003485607730198567,\n",
       "  0.00027000341890883253,\n",
       "  0.012254642667361629,\n",
       "  -0.0028341106306902673,\n",
       "  0.003678970749821684,\n",
       "  0.002399167512199505,\n",
       "  -0.0016443680461436926,\n",
       "  0.005197422529057395,\n",
       "  -0.0007617484196905788,\n",
       "  0.003132510408720179,\n",
       "  -0.0035919491424258035,\n",
       "  0.0071330550282218555,\n",
       "  0.0041518088609957425,\n",
       "  0.005141435499637918,\n",
       "  0.0050186890224985055,\n",
       "  0.003190791599581903,\n",
       "  -0.002640719076674158,\n",
       "  -0.005530433500286948,\n",
       "  -6.95218338028954e-05,\n",
       "  0.002255560146501702,\n",
       "  0.0036245811347481055,\n",
       "  0.0007411867889918313,\n",
       "  -0.001278371797743646,\n",
       "  -0.003950567230722093,\n",
       "  -0.002337392696451347,\n",
       "  -0.009052732579660092,\n",
       "  0.003774987931928639,\n",
       "  6.388508346513396e-05,\n",
       "  -0.0009138465493809237,\n",
       "  0.0011800681276810028,\n",
       "  0.004705038495500637],\n",
       " [0.011972285330563383,\n",
       "  -0.00793736974765411,\n",
       "  -0.0035168404361082665,\n",
       "  -0.00016329882853952194,\n",
       "  0.0019359231231473645,\n",
       "  0.005046088606375546,\n",
       "  -0.011958536065309788,\n",
       "  -0.006435597618951445,\n",
       "  0.01010744085821574,\n",
       "  0.006795887754433395,\n",
       "  -0.009985159457098599,\n",
       "  -0.013277409974596251,\n",
       "  -0.0015736052537733442,\n",
       "  -0.007207934504974374,\n",
       "  -0.005359512795263578,\n",
       "  -0.0044149337311086825,\n",
       "  -0.0034044359154211594,\n",
       "  0.007481919139499183,\n",
       "  -0.0036473277243728322,\n",
       "  -0.003041819888551786,\n",
       "  0.0009381551680174983,\n",
       "  0.007593091259535576,\n",
       "  0.0042012589587446855,\n",
       "  0.007007719958176585,\n",
       "  0.0055387966519520266,\n",
       "  -0.0041423913331386,\n",
       "  0.0037883937453348448,\n",
       "  0.009462650605698,\n",
       "  -0.006338065473958608,\n",
       "  0.005667015537492335,\n",
       "  -0.0032441468412702508,\n",
       "  0.004819749863022048],\n",
       " [-0.025334875414476772,\n",
       "  -0.010048183040083371,\n",
       "  -0.025759734093800262,\n",
       "  0.00464058271433329,\n",
       "  -0.008209082027875595,\n",
       "  0.010426552701696607,\n",
       "  -0.01198541115224603,\n",
       "  0.038829072839130535,\n",
       "  -0.007339945765535742,\n",
       "  -0.018267555614367513,\n",
       "  -0.002111575679165836,\n",
       "  0.02184413425290461,\n",
       "  0.01975851950790918,\n",
       "  -0.002110342576200329,\n",
       "  0.010544467080175889,\n",
       "  -0.002824549121420347,\n",
       "  0.02362760116832319,\n",
       "  -0.016516896132644694,\n",
       "  0.016416784662206838,\n",
       "  -0.010805730705938191,\n",
       "  -0.02339315004010129,\n",
       "  0.01824658892976727,\n",
       "  0.017655135842543655,\n",
       "  0.0014597116987504792,\n",
       "  0.004453768621271639,\n",
       "  0.01876161052549095,\n",
       "  -0.014327909535586877,\n",
       "  0.019813478569958486,\n",
       "  -0.0095507313464646,\n",
       "  -0.009696007986601713,\n",
       "  0.006994897145649068,\n",
       "  0.0078012383389463175],\n",
       " [0.0074695507471619306,\n",
       "  0.0007810284621494124,\n",
       "  -0.05411949486734712,\n",
       "  -0.04728161999094907,\n",
       "  0.04781885103550231,\n",
       "  -0.05046307962619546,\n",
       "  -0.011656721021715008,\n",
       "  0.03687936563078026,\n",
       "  -0.010084669071448714,\n",
       "  -0.027185846504297544,\n",
       "  -0.04955979495809053,\n",
       "  0.03686924470208808,\n",
       "  -0.040097840483508916,\n",
       "  0.013482985143237168,\n",
       "  -0.024940663000755734,\n",
       "  0.039292698666295596,\n",
       "  -0.014116003466191403,\n",
       "  -0.04270753263806624,\n",
       "  -0.044763121585424975,\n",
       "  0.00207467923069549,\n",
       "  -0.029432723267667802,\n",
       "  0.013020738366456846,\n",
       "  0.022608476565704045,\n",
       "  0.0035579278212901607,\n",
       "  0.008597829726535425,\n",
       "  -0.015314035225153235,\n",
       "  -0.019373430473114767,\n",
       "  0.012279395121539307,\n",
       "  0.0036284715264691745,\n",
       "  0.024636917353090523,\n",
       "  -0.0015469456416381607,\n",
       "  -0.0017183751167557226],\n",
       " [-0.11497187004235905,\n",
       "  0.0524846439195588,\n",
       "  -0.08309992230791044,\n",
       "  -0.030119115392871966,\n",
       "  -0.02872837249743685,\n",
       "  0.05592349699377427,\n",
       "  -0.06509108002718544,\n",
       "  -0.0005766742653719156,\n",
       "  -0.010583973848052727,\n",
       "  0.05357453285872081,\n",
       "  -0.017342300820729035,\n",
       "  0.07508101312761883,\n",
       "  0.008150272510926185,\n",
       "  0.08892316191613758,\n",
       "  0.0010764152025602815,\n",
       "  -0.08889875265766266,\n",
       "  -0.03545726079091848,\n",
       "  0.14549040245244532,\n",
       "  0.053584626711246586,\n",
       "  -0.009256665589162397,\n",
       "  0.024697949257287338,\n",
       "  -0.01051575038284157,\n",
       "  0.01910101520430393,\n",
       "  0.07585869211701257,\n",
       "  0.03496787190253613,\n",
       "  -0.036249107967683644,\n",
       "  -0.06467291279925595,\n",
       "  0.0473584668936134,\n",
       "  -0.07372363132211382,\n",
       "  0.0009825170653331493,\n",
       "  -0.06621741795317454,\n",
       "  0.17151108411948374],\n",
       " [-0.030247766577139165,\n",
       "  -0.0235385425947542,\n",
       "  0.007793451496386692,\n",
       "  0.043668614650310994,\n",
       "  -0.21462454548131782,\n",
       "  0.20869161117346838,\n",
       "  -0.07098492424216836,\n",
       "  0.2758495882619327,\n",
       "  -0.15643001988463548,\n",
       "  -0.01259783600635866,\n",
       "  -0.12952113335881904,\n",
       "  0.07480084973826935,\n",
       "  0.09834076530430033,\n",
       "  0.08845718193907563,\n",
       "  0.109450144980096,\n",
       "  -0.041182480025043225,\n",
       "  -0.12130022363951859,\n",
       "  0.20372473848657957,\n",
       "  -0.22361931326439893,\n",
       "  0.1797379237751768,\n",
       "  0.029181605006863044,\n",
       "  0.020243141535619805,\n",
       "  -0.17530341216526693,\n",
       "  0.06085831467764565,\n",
       "  0.1676265998477636,\n",
       "  0.03528985699491359,\n",
       "  -0.11581624075197884,\n",
       "  0.07676611551059256,\n",
       "  -0.0582699563497417,\n",
       "  -0.27917430307577207,\n",
       "  0.13484329768290756,\n",
       "  0.34823840440868536],\n",
       " [0.14937654668804703,\n",
       "  0.03900887954256678,\n",
       "  -0.38450233029330133,\n",
       "  -0.4388488395407162,\n",
       "  0.11836645216185712,\n",
       "  -0.22615930991580624,\n",
       "  0.19059859945930993,\n",
       "  0.08858135120760029,\n",
       "  0.26104360613310323,\n",
       "  -0.29635017605199926,\n",
       "  -0.7040975574570418,\n",
       "  0.31471595875746733,\n",
       "  -0.15712910190410403,\n",
       "  -0.03895549581431626,\n",
       "  0.2876763321213404,\n",
       "  -0.10009298296932713,\n",
       "  0.11854506638813944,\n",
       "  -0.023936871854724304,\n",
       "  0.10685352760982969,\n",
       "  0.01739810568963302,\n",
       "  0.16379367754125965,\n",
       "  -0.013397171919980744,\n",
       "  0.5012066065869383,\n",
       "  -0.13092932165701707,\n",
       "  -0.27407225322798245,\n",
       "  0.11738239011383489,\n",
       "  0.01745981755984966,\n",
       "  -0.21395071301015187,\n",
       "  -0.1926572930959282,\n",
       "  0.09847119604027016,\n",
       "  -0.32364521989783135,\n",
       "  0.020629312675561087],\n",
       " [-0.7618306276333413,\n",
       "  -0.2284197965094871,\n",
       "  0.2149433004065714,\n",
       "  -0.24850505449114285,\n",
       "  0.6354914864201565,\n",
       "  0.8847419168822963,\n",
       "  0.7845527808547565,\n",
       "  0.7466945803693681,\n",
       "  0.41318177731494554,\n",
       "  1.0706516998292523,\n",
       "  0.3118078263549537,\n",
       "  -0.0007576987231108081,\n",
       "  -0.35729888398961923,\n",
       "  0.2684271282883991,\n",
       "  -0.7189678080264706,\n",
       "  -0.6417327030235154,\n",
       "  -0.790130299177977,\n",
       "  -0.08877361347288573,\n",
       "  -0.0604897476318752,\n",
       "  -0.9084907161324897,\n",
       "  0.28654848256688414,\n",
       "  0.35793088265415796,\n",
       "  -1.0668782695076395,\n",
       "  0.2975186077979672,\n",
       "  0.8756888244442181,\n",
       "  0.5772670683362481,\n",
       "  0.5909657068301855,\n",
       "  0.6293016915341583,\n",
       "  0.37088345540518036,\n",
       "  -0.08492576875098588,\n",
       "  0.20597524585261504,\n",
       "  0.5363518872094458],\n",
       " [-0.28595018123265464,\n",
       "  -1.1614308279614267,\n",
       "  -0.6927451615028255,\n",
       "  0.0712289426005084,\n",
       "  0.7556370258317627,\n",
       "  0.22311684844520874,\n",
       "  0.12787995392812768,\n",
       "  0.09204615929049348,\n",
       "  1.482820052276971,\n",
       "  0.8644773675494456,\n",
       "  -0.8392934103753367,\n",
       "  0.7421781805142471,\n",
       "  1.3037262979171793,\n",
       "  0.8485790302655826,\n",
       "  0.6763940250579209,\n",
       "  0.061486139322083064,\n",
       "  0.1877290385327897,\n",
       "  -0.37670572419543713,\n",
       "  -1.681316549943762,\n",
       "  0.27363874374008995,\n",
       "  1.067948774529458,\n",
       "  -0.6230231223068002,\n",
       "  -1.3426654601351817,\n",
       "  0.7943500914130248,\n",
       "  -0.2748888787371663,\n",
       "  -1.0511555761288107,\n",
       "  -0.33255595609464894,\n",
       "  1.191506299779041,\n",
       "  0.10191263441460814,\n",
       "  0.6112477373493739,\n",
       "  1.1400003747492573,\n",
       "  -1.807263876586468],\n",
       " [0.9387026590314298,\n",
       "  3.338782291851153,\n",
       "  1.0490074319092006,\n",
       "  -0.23201813419020975,\n",
       "  1.9459368047115702,\n",
       "  -2.6143765020159804,\n",
       "  2.875701174403897,\n",
       "  1.7183156165828357,\n",
       "  1.3599646252488482,\n",
       "  -1.7494888045805668,\n",
       "  -0.3665159980101833,\n",
       "  -0.621771599521094,\n",
       "  0.6408842964255648,\n",
       "  2.0458754806189194,\n",
       "  -0.6055708274351571,\n",
       "  2.881059634781823,\n",
       "  0.6539013403967096,\n",
       "  3.3918654929807674,\n",
       "  -4.468792555075862,\n",
       "  0.6018911363966426,\n",
       "  1.089638912944646,\n",
       "  -0.7496690924730876,\n",
       "  0.16931934785042368,\n",
       "  -1.3479204990740303,\n",
       "  1.3764979721264508,\n",
       "  0.34871871333627097,\n",
       "  -2.450602661930888,\n",
       "  -2.718518550007946,\n",
       "  -0.24314743328348537,\n",
       "  0.26385686524011287,\n",
       "  0.5346917327499793,\n",
       "  -2.4040472749258313],\n",
       " [0.4482676791534778,\n",
       "  -3.15924155533084,\n",
       "  2.6600542851152262,\n",
       "  -1.607195355807378,\n",
       "  -1.2947666180100794,\n",
       "  0.5676941303711547,\n",
       "  2.880700832749783,\n",
       "  -1.1201418985926979,\n",
       "  -5.92417866611076,\n",
       "  -0.8125262049092873,\n",
       "  2.83063791629808,\n",
       "  1.1704249078696578,\n",
       "  2.0714791693685206,\n",
       "  -1.0667739928581332,\n",
       "  -0.12261920049652268,\n",
       "  0.49556484110762794,\n",
       "  2.377160081135032,\n",
       "  -0.9705908637850439,\n",
       "  4.917310823096321,\n",
       "  4.281357453621956,\n",
       "  3.5679605995038397,\n",
       "  -3.4364422000563613,\n",
       "  1.4797936774679739,\n",
       "  0.6695596303084641,\n",
       "  -1.9439215564763328,\n",
       "  5.424754814770294,\n",
       "  1.9997638214323106,\n",
       "  3.1920330009936766,\n",
       "  1.849623681677995,\n",
       "  0.7950793032607453,\n",
       "  3.6252672389985174,\n",
       "  2.7992822810876365],\n",
       " [10.700687550777147,\n",
       "  -4.3131268302868175,\n",
       "  -6.749797609098883,\n",
       "  -5.411004433980767,\n",
       "  1.1458865465007941,\n",
       "  -6.304383245003728,\n",
       "  -7.936176191920355,\n",
       "  4.90419823424934,\n",
       "  2.124621593251571,\n",
       "  -5.950763795692172,\n",
       "  -2.7932991605961908,\n",
       "  2.210463748867809,\n",
       "  -5.616011125210188,\n",
       "  -0.8807050238344474,\n",
       "  6.939923926551028,\n",
       "  -0.30879375088375866,\n",
       "  3.698911742707171,\n",
       "  -3.9829451054272167,\n",
       "  -7.104534278629717,\n",
       "  -2.6807941842216603,\n",
       "  12.862686153736455,\n",
       "  -6.911645344718563,\n",
       "  2.564646059274815,\n",
       "  -3.3580382892578067,\n",
       "  -5.946877244479386,\n",
       "  15.792907542882713,\n",
       "  -0.7279871701870934,\n",
       "  -5.346642889674268,\n",
       "  -5.647184405109359,\n",
       "  -4.164856344522701,\n",
       "  16.85642565809623,\n",
       "  -2.6552902845622937],\n",
       " [-5.949347101310381,\n",
       "  -14.921884389172952,\n",
       "  18.781119643724885,\n",
       "  30.028114800736844,\n",
       "  -8.83470864318474,\n",
       "  9.090468451877824,\n",
       "  7.691304286409191,\n",
       "  14.50086289285378,\n",
       "  -7.671826897879725,\n",
       "  -8.439917720798933,\n",
       "  -13.402018154334831,\n",
       "  -3.7999248891478064,\n",
       "  -8.227249590047094,\n",
       "  16.25109214426138,\n",
       "  11.81368737462676,\n",
       "  -6.49051916001996,\n",
       "  25.32810154074802,\n",
       "  -17.08988518572134,\n",
       "  -26.128400086986513,\n",
       "  -18.692431934791305,\n",
       "  9.904744199841748,\n",
       "  -23.468224410758005,\n",
       "  -15.907543347653322,\n",
       "  8.379161712556465,\n",
       "  -2.4991813575079695,\n",
       "  -4.349002413265685,\n",
       "  6.2958018148009245,\n",
       "  9.440298646983685,\n",
       "  -20.014885622350274,\n",
       "  24.534813332650877,\n",
       "  15.890744868088941,\n",
       "  -31.34884283139224],\n",
       " [12.659576800046871,\n",
       "  -6.149095618542437,\n",
       "  4.131705376265533,\n",
       "  -75.93270144893879,\n",
       "  -3.041212981779432,\n",
       "  29.983705559722953,\n",
       "  -15.580924336541122,\n",
       "  3.9371324488378567,\n",
       "  17.791413162854244,\n",
       "  11.596908403240219,\n",
       "  -9.569699072464061,\n",
       "  5.941152745581447,\n",
       "  -25.777091842389826,\n",
       "  -19.30614041328642,\n",
       "  33.78123443221136,\n",
       "  16.396846126400618,\n",
       "  4.327859794329168,\n",
       "  -42.67048584353802,\n",
       "  -2.84027869801172,\n",
       "  -24.179665582661208,\n",
       "  -18.245454019023466,\n",
       "  2.601127586710602,\n",
       "  7.485552487846244,\n",
       "  42.39722215607563,\n",
       "  -25.899863342087155,\n",
       "  6.960324157614351,\n",
       "  32.607880870198926,\n",
       "  28.68867258199272,\n",
       "  -37.80440441224152,\n",
       "  4.709672554530867,\n",
       "  28.027238013510566,\n",
       "  27.958791465426224],\n",
       " [-9.976288649010169,\n",
       "  20.02962044644151,\n",
       "  -32.09319048820548,\n",
       "  11.917243298727248,\n",
       "  104.09603712204591,\n",
       "  61.32051578528364,\n",
       "  -33.55350549889306,\n",
       "  13.344336139552746,\n",
       "  85.28983710106075,\n",
       "  -36.40473108628015,\n",
       "  -21.438665585710886,\n",
       "  -9.662249629858657,\n",
       "  -14.057274834761461,\n",
       "  47.2809515992558,\n",
       "  43.380719561353075,\n",
       "  -110.58951237348668,\n",
       "  -110.47613654346777,\n",
       "  -93.37172672397769,\n",
       "  20.899114923535773,\n",
       "  -152.14645534394444,\n",
       "  -5.0068443274100405,\n",
       "  -14.396880430321989,\n",
       "  -40.559198715861925,\n",
       "  -37.09828372886266,\n",
       "  89.05170387907715,\n",
       "  38.90616805621439,\n",
       "  33.5666211306724,\n",
       "  31.439300604273587,\n",
       "  112.0408497663349,\n",
       "  12.124770816560051,\n",
       "  28.575694117863893,\n",
       "  32.607528282953396],\n",
       " [96.03788622455045,\n",
       "  128.9785410309763,\n",
       "  -68.8221660892582,\n",
       "  -30.467243201711543,\n",
       "  -87.35579310556051,\n",
       "  -46.47224019158942,\n",
       "  54.28141906285353,\n",
       "  -46.19889075286341,\n",
       "  -26.227516809733885,\n",
       "  125.20648401771236,\n",
       "  -203.07358345141415,\n",
       "  143.13106843673452,\n",
       "  -172.25668558647683,\n",
       "  176.50528645742173,\n",
       "  38.93029901534709,\n",
       "  -195.29809002214515,\n",
       "  -276.9759065452495,\n",
       "  -10.88920164441801,\n",
       "  76.78529529542891,\n",
       "  105.98905378792078,\n",
       "  -88.89312605438005,\n",
       "  66.01545370722567,\n",
       "  -55.78892511170796,\n",
       "  -246.1252925635418,\n",
       "  100.90848886958553,\n",
       "  86.86124631044497,\n",
       "  -152.70616667668148,\n",
       "  36.95412985937826,\n",
       "  -36.35301652922209,\n",
       "  3.1904734322567396,\n",
       "  -129.55940733353,\n",
       "  -336.41432792019015],\n",
       " [111.6417452567896,\n",
       "  44.33377472354407,\n",
       "  96.03446694624377,\n",
       "  -136.81247174393957,\n",
       "  -226.91050587858464,\n",
       "  -63.79237945527494,\n",
       "  -233.69229800988177,\n",
       "  -270.7055292989822,\n",
       "  -103.18274227047242,\n",
       "  296.05995511188246,\n",
       "  649.8190240314688,\n",
       "  191.2493238156446,\n",
       "  314.15356799806995,\n",
       "  160.8653959056243,\n",
       "  -244.1729590825443,\n",
       "  -542.070030360414,\n",
       "  -242.23799901333376,\n",
       "  453.6574271642983,\n",
       "  -143.4482268692585,\n",
       "  146.73081597031103,\n",
       "  -364.4919344233005,\n",
       "  -58.86027097918402,\n",
       "  -477.0661905945542,\n",
       "  -538.377843132533,\n",
       "  489.84273679720366,\n",
       "  -263.2625156340092,\n",
       "  267.4556640830535,\n",
       "  -48.324140550624065,\n",
       "  -154.925128562745,\n",
       "  153.6905062649869,\n",
       "  188.30225417341637,\n",
       "  302.70023387459497],\n",
       " [395.1235959887344,\n",
       "  -41.78602064388755,\n",
       "  316.9181208925451,\n",
       "  -389.23243072182987,\n",
       "  34.114802813692265,\n",
       "  -370.6857763668535,\n",
       "  -537.3845157722193,\n",
       "  -333.66167068974727,\n",
       "  -217.32377232982165,\n",
       "  -97.57992074867994,\n",
       "  -620.4817984794655,\n",
       "  1907.1184952852295,\n",
       "  -43.10166043919674,\n",
       "  -330.46601130777736,\n",
       "  593.5054355119182,\n",
       "  -36.34557599212252,\n",
       "  332.4383907171423,\n",
       "  -776.9787031862044,\n",
       "  416.4240356062662,\n",
       "  -709.2076542877567,\n",
       "  849.0648753067276,\n",
       "  128.60591913560953,\n",
       "  -266.0824534850436,\n",
       "  1167.618432813602,\n",
       "  286.1276698489715,\n",
       "  -89.79673537215098,\n",
       "  258.08532381373,\n",
       "  603.3933866515233,\n",
       "  606.3662469432642,\n",
       "  -208.61417454469716,\n",
       "  -1153.6352278957756,\n",
       "  385.77106438753435]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f49957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
